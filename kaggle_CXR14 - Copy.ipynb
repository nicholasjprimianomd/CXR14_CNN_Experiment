{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import necessary packages\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "import glob \r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from keras.applications.densenet import DenseNet121\r\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\r\n",
    "from keras.models import Model\r\n",
    "from keras import backend as K\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from tensorflow import keras\r\n",
    "from keras import Sequential\r\n",
    "from tensorflow.keras import layers, models\r\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "data_entry = pd.read_csv('Data_Entry_2017.csv')\r\n",
    "all_imgs = glob.glob(\"dataset/*.png\")\r\n",
    "images = []\r\n",
    "\r\n",
    "mem_scale =  20\r\n",
    "selection_range = int(len(all_imgs)/mem_scale)\r\n",
    "\r\n",
    "for x in range(selection_range):\r\n",
    "    images.append(cv2.imread(all_imgs[x]))\r\n",
    "    image_dim = (512,512)\r\n",
    "    images[x] = cv2.resize(np.array(images[x]), image_dim)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "y = data_entry.iloc[:selection_range, 1]\r\n",
    "X = images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "for i in range(len(y)):\r\n",
    "    if y[i] == 'No Finding':\r\n",
    "        y[i] = 0\r\n",
    "    else:\r\n",
    "        y[i] = 1\r\n",
    "        \r\n",
    "y = pd.to_numeric(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "X_train = np.array(X_train)\r\n",
    "y_train = np.array(y_train)\r\n",
    "\r\n",
    "X_test = np.array(X_test)\r\n",
    "y_test = np.array(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2,  zoom_range = 0.2, horizontal_flip = True)\r\n",
    "training_set = train_datagen.flow(x = X_train, y = y_train, batch_size = 32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
    "test_set = test_datagen.flow(x = X_test, y = y_test, batch_size = 32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "nets = 1\r\n",
    "model = [0] * nets\r\n",
    "\r\n",
    "for j in range(nets):\r\n",
    "    model[j] = Sequential()\r\n",
    "    model[j].add(Conv2D(32,kernel_size=5,activation='relu',input_shape=[512, 512, 3]))\r\n",
    "    model[j].add(MaxPool2D(padding = 'valid', strides = 2))\r\n",
    "    model[j].add(Dropout(j*0.1))\r\n",
    "    model[j].add(Conv2D(64,kernel_size=5,activation='relu'))\r\n",
    "    model[j].add(MaxPool2D(padding = 'valid', strides = 2))\r\n",
    "    model[j].add(Dropout(j*0.1))\r\n",
    "    model[j].add(Flatten())\r\n",
    "    model[j].add(Dense(128, activation='relu'))\r\n",
    "    model[j].add(Dropout(j*0.1))\r\n",
    "    model[j].add(tf.keras.layers.Dense(units=218, activation='relu'))\r\n",
    "    model[j].add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\r\n",
    "    model[j].compile(optimizer=\"adam\", loss = 'binary_crossentropy', metrics=[\"accuracy\"])\r\n",
    "    model[j].fit(x = training_set, validation_data = test_set, epochs = 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "141/141 [==============================] - 154s 1s/step - loss: 0.9000 - accuracy: 0.5491 - val_loss: 0.6895 - val_accuracy: 0.5428\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Part 2 - Building the CNN\r\n",
    "'''\r\n",
    "# Initialising the CNN\r\n",
    "cnn = tf.keras.models.Sequential()\r\n",
    "\r\n",
    "# Step 1 - Convolution\r\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[1024, 1024, 3]))\r\n",
    "\r\n",
    "# Step 2 - Pooling\r\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=4, strides=2))\r\n",
    "\r\n",
    "# Adding second and third convolutional layers\r\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
    "\r\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
    "\r\n",
    "# Step 3 - Flattening\r\n",
    "cnn.add(tf.keras.layers.Flatten())\r\n",
    "\r\n",
    "# Step 4 - Full Connection\r\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\r\n",
    "\r\n",
    "# Step 5 - Output Layer\r\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\r\n",
    "\r\n",
    "# Part 3 - Training the CNN\r\n",
    "\r\n",
    "# Compiling the CNN\r\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\r\n",
    "\r\n",
    "# Training the CNN on the Training set and evaluating it on the Test set\r\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 5)'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Part 4 - Making a single prediction\r\n",
    "\r\n",
    "test_image = cv2.imread(all_imgs[selection_range])\r\n",
    "image_dim = (512,512)\r\n",
    "test_image = cv2.resize(test_image, image_dim)\r\n",
    "test_image = np.array(test_image)\r\n",
    "test_image = np.expand_dims(test_image, axis = 0)\r\n",
    "result = model[0].predict(test_image)\r\n",
    "\r\n",
    "\r\n",
    "if result[0][0] == 1:\r\n",
    "    prediction = 'pathology'\r\n",
    "else:\r\n",
    "    prediction = 'no pathology'\r\n",
    "\r\n",
    "\r\n",
    "print('Real:' + data_entry.iloc[selection_range + 1, 1])\r\n",
    "print('Print:' + prediction)\r\n",
    "\r\n",
    "cv2.imshow('Test Image', cv2.imread(all_imgs[selection_range + 1]))\r\n",
    "cv2.waitKey(0) # waits until a key is pressed\r\n",
    "cv2.destroyAllWindows() # destroys the window showing image\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real:Nodule\n",
      "Print:no pathology\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
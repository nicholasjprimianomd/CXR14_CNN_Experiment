{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Import necessary packages\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import cv2\r\n",
    "%matplotlib inline\r\n",
    "import os\r\n",
    "import pydicom as dicom\r\n",
    "import seaborn as sns\r\n",
    "import glob \r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from keras.applications.densenet import DenseNet121\r\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\r\n",
    "from keras.models import Model\r\n",
    "from keras import backend as K\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "from keras.models import load_model\r\n",
    "sns.set()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "data_entry = pd.read_csv('Data_Entry_2017.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "all_imgs = glob.glob(\"dataset/*.png\")\r\n",
    "images = []\r\n",
    "\r\n",
    "#rescale for out of memory error and testing speed\r\n",
    "mem_scale = 1000 \r\n",
    "\r\n",
    "selection_range = int(len(all_imgs)/mem_scale)\r\n",
    "\r\n",
    "\r\n",
    "for x in range(selection_range):\r\n",
    "    images.append(cv2.imread(all_imgs[x]))\r\n",
    "\r\n",
    "#cv2.imshow('Test',images_1[0])\r\n",
    "#cv2.waitKey(0) # waits until a key is pressed\r\n",
    "#cv2.destroyAllWindows() # destroys the window showing image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "y = data_entry.iloc[:selection_range, 1]\r\n",
    "X = images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "for i in range(len(y)):\r\n",
    "    if y[i] == 'No Finding':\r\n",
    "        y[i] = 0\r\n",
    "    else:\r\n",
    "        y[i] = 1\r\n",
    "y = pd.to_numeric(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\r\n",
    "                                                    test_size = 0.2,\r\n",
    "                                                    random_state = 1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "X_train = np.array(X_train)\r\n",
    "y_train = np.array(y_train)\r\n",
    "\r\n",
    "X_test = np.array(X_test)\r\n",
    "y_test = np.array(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
    "                                   shear_range = 0.2,\r\n",
    "                                   zoom_range = 0.2,\r\n",
    "                                   horizontal_flip = True)\r\n",
    "training_set = train_datagen.flow(x = X_train, y = y_train, batch_size = 32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
    "test_set = test_datagen.flow(x = X_test, y = y_test, batch_size = 32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Part 2 - Building the CNN\r\n",
    "\r\n",
    "# Initialising the CNN\r\n",
    "cnn = tf.keras.models.Sequential()\r\n",
    "\r\n",
    "# Step 1 - Convolution\r\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[1024, 1024, 3]))\r\n",
    "\r\n",
    "# Step 2 - Pooling\r\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=4, strides=2))\r\n",
    "\r\n",
    "# Adding second and third convolutional layers\r\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\r\n",
    "\r\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\r\n",
    "\r\n",
    "\r\n",
    "# Step 3 - Flattening\r\n",
    "cnn.add(tf.keras.layers.Flatten())\r\n",
    "\r\n",
    "# Step 4 - Full Connection\r\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\r\n",
    "\r\n",
    "# Step 5 - Output Layer\r\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Part 3 - Training the CNN\r\n",
    "\r\n",
    "# Compiling the CNN\r\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\r\n",
    "\r\n",
    "# Training the CNN on the Training set and evaluating it on the Test set\r\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 49s 11s/step - loss: 60.6241 - accuracy: 0.5506 - val_loss: 31.8005 - val_accuracy: 0.3478\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 36s 12s/step - loss: 13.8194 - accuracy: 0.5393 - val_loss: 10.7996 - val_accuracy: 0.6522\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 36s 10s/step - loss: 4.9093 - accuracy: 0.7079 - val_loss: 2.6280 - val_accuracy: 0.3478\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23a9c13b4f0>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Part 4 - Making a single prediction\r\n",
    "cv2.imread(all_imgs[selection_range + 1])\r\n",
    "\r\n",
    "test_image = cv2.imread(all_imgs[selection_range + 1])\r\n",
    "test_image = np.array(test_image)\r\n",
    "test_image = np.expand_dims(test_image, axis = 0)\r\n",
    "result = cnn.predict(test_image)\r\n",
    "\r\n",
    "if result[0][0] == 1:\r\n",
    "    prediction = 'pathology'\r\n",
    "else:\r\n",
    "    prediction = 'no pathology'\r\n",
    "    \r\n",
    "print(prediction)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "no pathology\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}